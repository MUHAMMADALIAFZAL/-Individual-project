# -*- coding: utf-8 -*-
"""LLM assignment 02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DG00G67RbL4_RcDVx3r6ygOFutba-fa-
"""

# Install required packages
!pip install torch torchvision transformers datasets matplotlib pandas scikit-learn wordcloud
!pip install --upgrade --force-reinstall fsspec datasets

# ----- Imports -----
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from transformers import BertTokenizer, BertForSequenceClassification
from torch.optim import AdamW
from datasets import load_dataset
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
# ----- Style for Plots -----
plt.style.use('ggplot')

# ----- Device Setup -----
gpu = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Using device:", gpu)

# ----- Load IMDb Dataset -----
imdb_raw = load_dataset("imdb")
reviews_df = pd.concat([
    pd.DataFrame(imdb_raw['train']),
    pd.DataFrame(imdb_raw['test'])
], ignore_index=True)

# Shuffle & Subsample for Quick Demo (adjust as needed)
shuffled_df = reviews_df.sample(frac=1, random_state=22).reset_index(drop=True)
split_set, holdout_set = train_test_split(
    shuffled_df,
    train_size=4000,
    test_size=800,
    stratify=shuffled_df['label'],
    random_state=22
)

# Print label balance for sanity check
print(split_set['label'].value_counts(), '\n', holdout_set['label'].value_counts())

# ----- Visualization: Class Balance -----
fig, axis = plt.subplots(figsize=(5,3))
bar_colors = ['#fbb13c', '#2ec4b6']
split_set['label'].value_counts().plot(kind='bar', color=bar_colors, ax=axis, edgecolor='black')
axis.set_title('IMDb Review Labels (Sample Set)', fontsize=12, fontweight='bold')
axis.set_xlabel('Sentiment')
axis.set_ylabel('Number')
axis.set_xticklabels(['Negative', 'Positive'], rotation=0)
axis.grid(axis='y', linestyle=':', alpha=0.3)
plt.tight_layout()
plt.show()

# ----- Visualization: Review Length -----
split_set['tokens'] = split_set['text'].apply(lambda t: len(t.split()))
plt.figure(figsize=(7,3))
plt.hist(split_set['tokens'], bins=50, color='#7b2ff2', edgecolor='#f357a8', alpha=0.82)
plt.title('Token Count Distribution in Reviews', fontsize=12, fontweight='bold')
plt.xlabel('Number of Words')
plt.ylabel('Frequency')
plt.grid(axis='y', linestyle='--', alpha=0.25)
plt.tight_layout()
plt.show()

# ----- Word Clouds -----
neg_words = " ".join(split_set[split_set['label']==0]['text'])
pos_words = " ".join(split_set[split_set['label']==1]['text'])

wordcloud_neg = WordCloud(width=600, height=230, background_color='white', colormap='winter').generate(neg_words)
plt.figure(figsize=(8,3))
plt.imshow(wordcloud_neg, interpolation='bilinear')
plt.axis('off')
plt.title('Negative IMDb Word Cloud', fontsize=12, color='#0077b6')
plt.tight_layout()
plt.show()

wordcloud_pos = WordCloud(width=600, height=230, background_color='white', colormap='autumn').generate(pos_words)
plt.figure(figsize=(8,3))
plt.imshow(wordcloud_pos, interpolation='bilinear')
plt.axis('off')
plt.title('Positive IMDb Word Cloud', fontsize=12, color='#f77f00')
plt.tight_layout()
plt.show()

# ----- Data Preparation for Model -----
input_texts = split_set['text'].tolist()
input_labels = split_set['label'].tolist()
eval_texts = holdout_set['text'].tolist()
eval_labels = holdout_set['label'].tolist()

# ----- Custom PyTorch Dataset Class -----
class ReviewTorchSet(Dataset):
    def __init__(self, samples, classes, bert_tokenizer, max_size):
        self.samples = samples
        self.classes = classes
        self.tokenizer = bert_tokenizer
        self.max_size = max_size
    def __len__(self):
        return len(self.samples)
    def __getitem__(self, idx):
        enc = self.tokenizer(
            self.samples[idx],
            truncation=True,
            padding='max_length',
            max_length=self.max_size,
            return_tensors='pt'
        )
        pack = {k: v.squeeze(0) for k, v in enc.items()}
        pack['labels'] = torch.tensor(self.classes[idx], dtype=torch.long)
        return pack

# ----- Tokenizer & DataLoader -----
sent_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
max_length = 192

torchset_train = ReviewTorchSet(input_texts, input_labels, sent_tokenizer, max_length)
torchset_eval = ReviewTorchSet(eval_texts, eval_labels, sent_tokenizer, max_length)

dl_train = DataLoader(torchset_train, batch_size=18, shuffle=True)
dl_eval = DataLoader(torchset_eval, batch_size=18)

# ----- Model Setup -----
bert_sentiment = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
bert_sentiment = bert_sentiment.to(gpu)

optim = AdamW(bert_sentiment.parameters(), lr=2.5e-5)
loss_fn = nn.CrossEntropyLoss()

# ----- Show Example Inputs -----
print("\nExamples (before training):\n")
for j in range(2):
    print(f"Review: {eval_texts[j][:100]}...")
    print(f"Label: {eval_labels[j]}")
    print()

# ----- Training Loop -----
epochs = 10 # For quick demo. For best results, use more.
loss_curve = []

for ep in range(epochs):
    bert_sentiment.train()
    cumu_loss = 0
    for batch in dl_train:
        ids = batch['input_ids'].to(gpu)
        mask = batch['attention_mask'].to(gpu)
        labs = batch['labels'].to(gpu)
        optim.zero_grad()
        outs = bert_sentiment(input_ids=ids, attention_mask=mask, labels=labs)
        loss = outs.loss
        loss.backward()
        optim.step()
        cumu_loss += loss.item()
    epoch_loss = cumu_loss / len(dl_train)
    loss_curve.append(epoch_loss)
    print(f"Epoch {ep+1}/{epochs} | Loss: {epoch_loss:.4f}")

# ----- Plot Training Loss -----
plt.figure(figsize=(6,4))
plt.plot(range(1, epochs+1), loss_curve, marker='s', linestyle='-', color='#08a045', linewidth=2)
plt.title('Training Loss per Epoch', fontsize=13, fontweight='bold')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True, linestyle='-.', alpha=0.5)
plt.tight_layout()
plt.show()

# ----- Model Evaluation -----
bert_sentiment.eval()
guess = []
truth = []

with torch.no_grad():
    for batch in dl_eval:
        ids = batch['input_ids'].to(gpu)
        mask = batch['attention_mask'].to(gpu)
        labs = batch['labels'].to(gpu)
        output = bert_sentiment(input_ids=ids, attention_mask=mask)
        preds = torch.argmax(output.logits, dim=1)
        guess.extend(preds.cpu().numpy())
        truth.extend(labs.cpu().numpy())

acc = accuracy_score(truth, guess)
f1 = f1_score(truth, guess)

print(f"\nIMDb Test Accuracy: {acc:.4f}")
print(f"IMDb Test F1 Score: {f1:.4f}")

cmatrix = confusion_matrix(truth, guess)
labels = ['Negative', 'Positive']
disp = ConfusionMatrixDisplay(confusion_matrix=cmatrix, display_labels=labels)
fig, ax = plt.subplots(figsize=(5,4))
disp.plot(cmap='Blues', ax=ax, colorbar=False)
plt.title('IMDb Prediction Confusion Matrix', fontsize=12, color='#36486b')
plt.grid(False)
plt.show()

# ----- Show Predictions on Samples -----
print("\nSample predictions:\n")
for i in range(4):
    print(f"Text: {eval_texts[i][:110]}...")
    print(f"True Label: {eval_labels[i]} | Predicted: {guess[i]}")
    print()